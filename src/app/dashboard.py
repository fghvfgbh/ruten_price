# src/app/dashboard.py (Cloud éƒ¨ç½²æœ€çµ‚ç‰ˆ)

import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime
import logging
from sqlalchemy import create_engine 

# --- [ä¿®æ­£å€å¡Š] å°å…¥è·¯å¾‘èˆ‡ç’°å¢ƒä¿®æ­£ ---
import sys
import os

current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '..', '..'))

if project_root not in sys.path:
    sys.path.append(project_root)

# åŒ¯å…¥è³‡æ–™åº«ç›¸é—œæ¨¡çµ„ (ç¾åœ¨å¯ä»¥æ­£ç¢ºå°å…¥äº†)
from src.database.__init__ import get_db, init_db, engine 
from src.database.crud import create_or_update_product, add_price_record
from src.scraper.core import setup_driver, scrape_search_page # å°å…¥çˆ¬èŸ²æ ¸å¿ƒ
from config import INITIAL_TRACKING_KEYWORDS, MAX_PAGES_TO_SCRAPE # å°å…¥é…ç½®
# --------------------------------------------------------

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- æ–°å¢ï¼šé›²ç«¯æ‰‹å‹•å•Ÿå‹•çˆ¬èŸ²å‡½å¼ ---
def run_scraper_manually():
    """åœ¨ Streamlit Cloud ç’°å¢ƒä¸­æ‰‹å‹•å•Ÿå‹•çˆ¬èŸ²ä»»å‹™ã€‚"""
    st.info("çˆ¬èŸ²ä»»å‹™å•Ÿå‹•ä¸­ï¼Œé€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“ï¼Œè«‹ä¿æŒç¶²é é–‹å•Ÿ...")
    
    # ä½¿ç”¨ st.status é¡¯ç¤ºå³æ™‚é€²åº¦ (Streamlit å…§å»ºåŠŸèƒ½)
    with st.status("æ­£åœ¨é‹è¡Œçˆ¬èŸ²...", expanded=True) as status:
        
        init_db() # ç¢ºä¿è³‡æ–™åº«çµæ§‹å­˜åœ¨
        
        driver = None
        db = None
        total_items_scraped = 0
        
        try:
            status.update(label="1/3 æ­£åœ¨å•Ÿå‹• WebDriver (Chrome)", state="running", expanded=True)
            driver = setup_driver()
            if not driver:
                status.update(label="WebDriver å•Ÿå‹•å¤±æ•—ï¼è«‹æª¢æŸ¥ Cloud æ—¥èªŒã€‚", state="error")
                return

            db_generator = get_db()
            db = next(db_generator)
            
            # 2. è¿­ä»£æ‰€æœ‰é—œéµå­—ä¸¦çˆ¬å–æ•¸æ“š
            for term in INITIAL_TRACKING_KEYWORDS:
                for page in range(1, MAX_PAGES_TO_SCRAPE + 1):
                    
                    status.update(label=f"2/3 æ­£åœ¨çˆ¬å–é—œéµå­—: {term} (é ç¢¼: {page})...", state="running")
                    scraped_items = scrape_search_page(driver, term, page=page)
                    
                    if not scraped_items and page > 1: break
                    
                    for item in scraped_items:
                        product = create_or_update_product(db, **item)
                        if product:
                            add_price_record(db, product.id, item['price'])
                            total_items_scraped += 1
            
            # 3. æäº¤ä¸¦å®Œæˆ
            db.commit()
            status.update(label=f"âœ… æ•¸æ“šæ›´æ–°å®Œæˆï¼å…±è¨ˆæ–°å¢ {total_items_scraped} æ¢åƒ¹æ ¼è¨˜éŒ„ã€‚", state="complete")
            
        except Exception as e:
            if db: db.rollback()
            status.update(label=f"âŒ çˆ¬èŸ²ä»»å‹™åŸ·è¡ŒæœŸé–“ç™¼ç”ŸéŒ¯èª¤ï¼š{e}", state="error")
            logging.error(f"Cloud Scraper Error: {e}")
        finally:
            if driver: driver.quit()
            st.cache_data.clear() # æ¸…é™¤å¿«å–ï¼Œå¼·åˆ¶é‡æ–°è¼‰å…¥æ•¸æ“š
            st.rerun() # é‹è¡Œå®Œæˆå¾Œï¼Œé‡æ–°è¼‰å…¥æ‡‰ç”¨ç¨‹å¼ä»¥é¡¯ç¤ºæ–°æ•¸æ“š

    
# --- (å…¶é¤˜æ•¸æ“šè¼‰å…¥å’Œåœ–è¡¨å‡½å¼ä¿æŒä¸è®Š) ---
# ... (load_all_history_data, load_data_to_df, display_price_history, display_keyword_average_trend å‡½å¼è«‹ä¿æŒä¸è®Š) ...


# --- Streamlit æ‡‰ç”¨ä¸»é«” ---
def main():
    st.set_page_config(layout="wide", page_title="éœ²å¤©åƒ¹æ ¼è¿½è¹¤å„€è¡¨æ¿")
    st.title("ğŸ’° éœ²å¤©æ‹è³£åƒ¹æ ¼è¶¨å‹¢è¿½è¹¤å„€è¡¨æ¿")
    st.markdown("---")

    # 1. åˆå§‹åŒ–è³‡æ–™åº« 
    init_db()
    
    # 2. çˆ¬èŸ²å•Ÿå‹•æŒ‰éˆ• (åœ¨ Tab ä¹‹å¤–)
    if st.button("æ‰‹å‹•æ›´æ–°æ•¸æ“š (é‹è¡Œçˆ¬èŸ²)"):
        run_scraper_manually()

    st.markdown("---")


    tab1, tab2 = st.tabs(["ğŸ“Š å–®å“æ•¸æ“šæ¦‚è¦½", "ğŸ“ˆ é—œéµå­—è¶¨å‹¢åˆ†æ"])

    # ... (Tab 1 å’Œ Tab 2 çš„é‚è¼¯ä¿æŒä¸è®Šï¼Œå› ç‚ºå®ƒå€‘æœƒèª¿ç”¨ st.cache_data) ...
    # ... (è«‹å°‡ Tab 1 å’Œ Tab 2 çš„å®Œæ•´é‚è¼¯è¤‡è£½åˆ°é€™è£¡) ...

    # ç”±æ–¼ç¯‡å¹…é™åˆ¶ï¼Œè«‹æ‚¨å°‡ Tab 1 å’Œ Tab 2 çš„å®Œæ•´é‚è¼¯å¾ä¸Šä¸€è¼ªçš„å®Œæ•´ç‰ˆæœ¬ä¸­è¤‡è£½éä¾†ã€‚
    
    # é€™è£¡å°‡ä½¿ç”¨é ç•™ä½ç½®ï¼Œç¢ºä¿ç¨‹å¼çµæ§‹å®Œæ•´
    with tab1:
        st.header("å–®å“æ•¸æ“šæ¦‚è¦½")
        # è«‹ç¢ºä¿é€™è£¡æœ‰ load_data_to_df() å’Œå¾ŒçºŒçš„ selectbox/dataframe é‚è¼¯
        pass 
    
    with tab2:
        st.header("é—œéµå­—å¸‚å ´è¶¨å‹¢åˆ†æ")
        # è«‹ç¢ºä¿é€™è£¡æœ‰ load_all_history_data() å’Œ display_keyword_average_trend é‚è¼¯
        pass


if __name__ == '__main__':
    main()
